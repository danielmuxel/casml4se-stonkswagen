{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8b547f118e0665",
   "metadata": {},
   "source": [
    "## Carefull, very much work in progress\n",
    "Currently, uses a single items\n",
    "This may not work\n",
    "Other ideas:\n",
    "Using multiple items\n",
    "\n",
    "Uses scaler, may not be working correctly."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T13:20:42.482094Z",
     "start_time": "2025-11-30T13:20:42.477980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext dotenv\n",
    "%reload_ext dotenv\n",
    "%dotenv"
   ],
   "id": "ca3558966774fcd",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T13:20:44.954348Z",
     "start_time": "2025-11-30T13:20:42.607634Z"
    }
   },
   "source": [
    "import mlflow\n",
    "from darts.models import XGBModel\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "345cc72d6ce02647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T13:20:50.792389Z",
     "start_time": "2025-11-30T13:20:45.006241Z"
    }
   },
   "source": [
    "# Download source data from s3\n",
    "from gw2ml.data.s3_sync import download_folder_from_s3\n",
    "\n",
    "import os\n",
    "\n",
    "datapath = os.path.join(os.getenv('DATA_PATH'), 'train_xgboost')\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "\n",
    "\n",
    "download_folder_from_s3(s3_folder_prefix='datasources/gw2/raw/1762686861', local_folder=datapath)\n",
    "df = pd.read_csv(f'{datapath}/Copper Ore.csv', delimiter=\";\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ost-s3/datasources/gw2/raw/1762686861\n",
      "Target: /home/lukas/Documents/Github/casml4se-stonkswagen/data/train_xgboost\n",
      "\n",
      "Found 60 files to download\n",
      "\n",
      "✓ +1 Agony Infusion.csv\n",
      "✓ Auric Sliver.csv\n",
      "✓ Bag of Coffee Beans.csv\n",
      "✓ Bag of Sugar.csv\n",
      "✓ Black Lion Chest.csv\n",
      "✓ Bowl of Candy Corn Custard.csv\n",
      "✓ Choya Spine.csv\n",
      "✓ Congealed Putrescence.csv\n",
      "✓ Copper Ore.csv\n",
      "✓ Cup of Spiced Apple Cider.csv\n",
      "✓ Elder Wood Log.csv\n",
      "✓ Eye of Kormir.csv\n",
      "✓ Flawless Snowflake.csv\n",
      "✓ Fried Golden Dumpling.csv\n",
      "✓ Glass of Buttered Spirits.csv\n",
      "✓ Glob of Ectoplasm.csv\n",
      "✓ Gold Ingot.csv\n",
      "✓ Gold Ore.csv\n",
      "✓ Gossamer Scrap.csv\n",
      "✓ Green Wood Log.csv\n",
      "✓ Handful of Red Lentils.csv\n",
      "✓ Iron Ore.csv\n",
      "✓ Jug of Water.csv\n",
      "✓ Jute Scrap.csv\n",
      "✓ Large Bone.csv\n",
      "✓ Large Claw.csv\n",
      "✓ Large Fang.csv\n",
      "✓ Large Scale.csv\n",
      "✓ Ley-Infused Sand.csv\n",
      "✓ Lucent Mote.csv\n",
      "✓ Lucky Draketail.csv\n",
      "✓ Lucky Prismatic Rocket.csv\n",
      "✓ Lump of Coal.csv\n",
      "✓ Mithril Ore.csv\n",
      "✓ Mystic Coin.csv\n",
      "✓ Orichalcum Ore.csv\n",
      "✓ Piece of Candy Corn.csv\n",
      "✓ Piece of Common Unidentified Gear.csv\n",
      "✓ Piece of Unidentified Gear.csv\n",
      "✓ Piece of Zhaitaffy.csv\n",
      "✓ Pile of Flax Seeds.csv\n",
      "✓ Pile of Glittering Dust.csv\n",
      "✓ Pile of Incandescent Dust.csv\n",
      "✓ Potent Venom Sac.csv\n",
      "✓ Pulsing Brandspark.csv\n",
      "✓ Rawhide Leather Section.csv\n",
      "✓ Shard of Glory.csv\n",
      "✓ Silver Ore.csv\n",
      "✓ Snowflake.csv\n",
      "✓ Soft Wood Log.csv\n",
      "✓ Spring Roll.csv\n",
      "✓ Steamed Red Dumpling.csv\n",
      "✓ Strawberry Ghost.csv\n",
      "✓ Thick Leather Section.csv\n",
      "✓ Thin Leather Section.csv\n",
      "✓ Tiny Snowflake.csv\n",
      "✓ Trick-or-Treat Bag.csv\n",
      "✓ Ugly Wool Hat.csv\n",
      "✓ Ugly Wool Sock.csv\n",
      "✓ Watchwork Sprocket.csv\n",
      "\n",
      "==================================================\n",
      "Download Summary:\n",
      "  Downloaded: 60/60\n",
      "  Skipped: 0/60\n",
      "  Failed: 0/60\n",
      "  Location: /home/lukas/Documents/Github/casml4se-stonkswagen/data/train_xgboost\n",
      "  Source: ost-s3/datasources/gw2/raw/1762686861\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a42e025ef27a1d8b",
   "metadata": {},
   "source": [
    "from darts import TimeSeries\n",
    "#value_cols = [\"buy_unit_price\",\"sell_quantity\", \"sell_unit_price\", \"buy_quantity\"]\n",
    "\n",
    "value_cols = [\"sell_unit_price\"]\n",
    "\n",
    "tsdf = df[value_cols + ['fetched_at']].copy()\n",
    "# series = TimeSeries.from_dataframe(df, time_col=\"fetched_at\")\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "tsdf['fetched_at'] = pd.to_datetime(tsdf['fetched_at'])\n",
    "# Localize timezone to UTC if it has timezone info, or remove it\n",
    "if tsdf['fetched_at'].dt.tz is not None:\n",
    "    tsdf['fetched_at'] = tsdf['fetched_at'].dt.tz_localize(None)\n",
    "tsdf = tsdf.set_index('fetched_at')\n",
    "#value_cols = [\"buy_unit_price\"]  #ARIMA only univariate !\n",
    "\n",
    "# Resample to exact 5-minute intervals, forward-filling missing values\n",
    "tsdf_resampled = tsdf[value_cols].resample('5min').mean().interpolate(method='linear')\n",
    "\n",
    "# Create TimeSeries (no need for fill_missing_dates now)\n",
    "series = TimeSeries.from_dataframe(tsdf_resampled, value_cols=value_cols)\n",
    "series.plot();\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91c97e369894affa",
   "metadata": {},
   "source": [
    "# Scaling the data\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "scaler = Scaler()\n",
    "series_scaled = scaler.fit_transform(series)\n",
    "series_scaled.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e083a011af3bf4",
   "metadata": {},
   "source": [
    "train, val = series_scaled.split_after(0.75)\n",
    "#train, val = series.split_after(0.75)\n",
    "train.plot(label=\"training\")\n",
    "val.plot(label=\"validation\");\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69ec7938ded1a375",
   "metadata": {},
   "source": [
    "from darts.metrics import mape\n",
    "from darts.models import XGBModel\n",
    "\n",
    "model = XGBModel(\n",
    "    lags=48,                     # use the last 12 observations as features\n",
    "    lags_past_covariates=None,   # no past covariates by default\n",
    "    lags_future_covariates=None, # no future covariates by default\n",
    "    output_chunk_length=1,       # one‑step‑ahead forecasts\n",
    "    n_estimators=200,            # number of boosting rounds\n",
    "    max_depth=40,                 # tree depth\n",
    "    learning_rate=0.1,           # shrinkage factor\n",
    "    subsample=0.8,               # row sampling ratio\n",
    "    colsample_bytree=0.8,        # column sampling ratio\n",
    "    reg_alpha=0.0,               # L1 regularisation\n",
    "    reg_lambda=0.0,              # L2 regularisation\n",
    "    #early_stopping_rounds=20,   # stop if validation error doesn’t improve\n",
    "    device=\"cuda:0\" # this is broken\n",
    ")\n",
    "model.fit(train, val_series=val)\n",
    "forecast = model.predict(n=len(val), series=train)\n",
    "error = mape(val, forecast)\n",
    "print(f\"MAPE: {error:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0137835ac7543ef",
   "metadata": {},
   "source": [
    "forecast_reversed = scaler.inverse_transform(forecast)\n",
    "val_reversed = scaler.inverse_transform(val)\n",
    "forecast_reversed.plot()\n",
    "val_reversed.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"xgboost_univariate\")\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")"
   ],
   "id": "1874976893ec7a91",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4166e06be5234c79",
   "metadata": {},
   "source": [
    "from darts.metrics import mape\n",
    "from darts.models import XGBModel\n",
    "\n",
    "\n",
    "best_mape = float('inf')\n",
    "best_params = None\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "lags_range = [24, 48, 72]\n",
    "n_estimators_range = [100, 200, 300]\n",
    "max_depth_range = [20, 40, 60]\n",
    "learning_rate_range = [0.05, 0.1, 0.2]\n",
    "subsample_range = [0.6, 0.8, 1.0]\n",
    "colsample_bytree_range = [0.6, 0.8, 1.0]\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = len(lags_range) * len(n_estimators_range) * len(max_depth_range) * \\\n",
    "                    len(learning_rate_range) * len(subsample_range) * len(colsample_bytree_range)\n",
    "\n",
    "# Parent run for the hyperparameter search\n",
    "with mlflow.start_run(run_name=\"XGBOOST_Hyperparameter_Search\"):\n",
    "\n",
    "    # Log search configuration\n",
    "    mlflow.log_param(\"search_lags\", str(lags_range))\n",
    "    mlflow.log_param(\"search_n_estimators\", str(n_estimators_range))\n",
    "    mlflow.log_param(\"search_max_depth\", str(max_depth_range))\n",
    "    mlflow.log_param(\"search_learning_rate\", str(learning_rate_range))\n",
    "    mlflow.log_param(\"search_subsample\", str(subsample_range))\n",
    "    mlflow.log_param(\"search_colsample_bytree\", str(colsample_bytree_range))\n",
    "    mlflow.log_param(\"total_combinations\", total_combinations)\n",
    "\n",
    "    # Create progress bar\n",
    "    combination_count = 0\n",
    "    for lags in lags_range:\n",
    "        for n_estimators in n_estimators_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                for learning_rate in learning_rate_range:\n",
    "                    for subsample in subsample_range:\n",
    "                        for colsample_bytree in colsample_bytree_range:\n",
    "                            combination_count += 1\n",
    "\n",
    "                            print(f\"Testing XGBModel {combination_count}/{total_combinations}: \"\n",
    "                                  f\"lags={lags}, n_est={n_estimators}, depth={max_depth}, \"\n",
    "                                  f\"lr={learning_rate}, sub={subsample}, col={colsample_bytree}\")\n",
    "\n",
    "                            # Child run for each parameter combination\n",
    "                            with mlflow.start_run(run_name=f\"XGB_{lags}_{n_estimators}_{max_depth}_{learning_rate}_{subsample}_{colsample_bytree}\", nested=True):\n",
    "                                # Log parameters\n",
    "                                mlflow.log_param(\"lags\", lags)\n",
    "                                mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "                                mlflow.log_param(\"max_depth\", max_depth)\n",
    "                                mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "                                mlflow.log_param(\"subsample\", subsample)\n",
    "                                mlflow.log_param(\"colsample_bytree\", colsample_bytree)\n",
    "                                mlflow.log_param(\"output_chunk_length\", 1)\n",
    "                                mlflow.log_param(\"reg_alpha\", 0.0)\n",
    "                                mlflow.log_param(\"reg_lambda\", 0.0)\n",
    "                                mlflow.log_param(\"model_type\", \"XGBModel\")\n",
    "\n",
    "                                try:\n",
    "                                    # Train model\n",
    "                                    model = XGBModel(\n",
    "                                        lags=lags,\n",
    "                                        lags_past_covariates=None,\n",
    "                                        lags_future_covariates=None,\n",
    "                                        output_chunk_length=1,\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        max_depth=max_depth,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        subsample=subsample,\n",
    "                                        colsample_bytree=colsample_bytree,\n",
    "                                        reg_alpha=0.0,\n",
    "                                        reg_lambda=0.0,\n",
    "                                        # device=\"cuda:0\"  # commented out as is broken\n",
    "                                    )\n",
    "                                    model.fit(train)\n",
    "\n",
    "                                    # Make predictions\n",
    "                                    forecast = model.predict(len(val))\n",
    "                                    error = mape(val, forecast)\n",
    "\n",
    "                                    # Log metrics\n",
    "                                    mlflow.log_metric(\"mape\", error)\n",
    "                                    mlflow.log_metric(\"mape_percentage\", error)\n",
    "\n",
    "                                    # Log model artifact\n",
    "                                    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "                                    # Check if this is the best model so far\n",
    "                                    if error < best_mape:\n",
    "                                        best_mape = error\n",
    "                                        best_params = {\n",
    "                                            'lags': lags,\n",
    "                                            'n_estimators': n_estimators,\n",
    "                                            'max_depth': max_depth,\n",
    "                                            'learning_rate': learning_rate,\n",
    "                                            'subsample': subsample,\n",
    "                                            'colsample_bytree': colsample_bytree\n",
    "                                        }\n",
    "                                        print(f\"New best: {best_params} with MAPE: {error:.2f}%\")\n",
    "\n",
    "                                        # Log as best model in parent run\n",
    "                                        mlflow.log_metric(\"best_mape\", error)\n",
    "                                        mlflow.log_param(\"best_lags\", lags)\n",
    "                                        mlflow.log_param(\"best_n_estimators\", n_estimators)\n",
    "                                        mlflow.log_param(\"best_max_depth\", max_depth)\n",
    "                                        mlflow.log_param(\"best_learning_rate\", learning_rate)\n",
    "                                        mlflow.log_param(\"best_subsample\", subsample)\n",
    "                                        mlflow.log_param(\"best_colsample_bytree\", colsample_bytree)\n",
    "\n",
    "                                except Exception as e:\n",
    "                                    # Log failed runs\n",
    "                                    mlflow.log_param(\"status\", \"failed\")\n",
    "                                    mlflow.log_param(\"error\", str(e))\n",
    "                                    print(f\"Failed XGBModel combination: {str(e)}\")\n",
    "\n",
    "    # Log final results in parent run\n",
    "    mlflow.log_metric(\"final_best_mape\", best_mape)\n",
    "    mlflow.log_param(\"final_best_params\", str(best_params))\n",
    "\n",
    "    print(f\"\\nBest model: {best_params} with MAPE: {best_mape:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4deabe5682ef607",
   "metadata": {},
   "source": [
    "from darts.models import NaiveDrift, VARIMA\n",
    "from darts.metrics import mape\n",
    "\n",
    "def eval_model(model):\n",
    "\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(len(val))\n",
    "    print(f\"model {model} obtains MAPE: {mape(val, forecast):.2f}%\")\n",
    "\n",
    "\n",
    "eval_model(NaiveDrift())\n",
    "eval_model(VARIMA())\n",
    "eval_model(VARIMA(p=3, d=1, q=2))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2622cd75e660b8cf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
