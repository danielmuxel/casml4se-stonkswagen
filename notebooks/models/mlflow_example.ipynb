{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd647aefa1c750d",
   "metadata": {},
   "source": [
    "# Load environment variables.\n",
    "\n",
    "## These are used to configure the mlflow library. And should point to your mlflow instance.  \n",
    "### MLFLOW_TRACKING_URI\n",
    "this is the main mlflow server, same as where the webui runs.  \n",
    "Normally on port 5000\n",
    "### MLFLOW_S3_ENDPOINT_URL\n",
    "this is the S3/artifact store. Is a minio instance(see compose file).  \n",
    "It is required because the mlflow client will push artifacts directly to the s3 store, not the main mlflow api.  \n",
    "Default runs on port 9000\n",
    "\n",
    "\n",
    "This example uses jupyter magicks to import the .env file.  \n",
    "Be careful, the .env for the docker-compose and the .env for the project are treated separately, and this should be the .env from the project root.  \n",
    "\n",
    "**Magicks for notebooks:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8877339b4e793bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:56:41.486045Z",
     "start_time": "2025-11-20T14:56:41.480470Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c0f0a6a03bc79",
   "metadata": {},
   "source": [
    "**Or dotenv for normal python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0c85c8e0ec5113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:56:42.056258Z",
     "start_time": "2025-11-20T14:56:42.052513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98756338b9fb7a",
   "metadata": {},
   "source": [
    "**Required env variables**  \n",
    "These environment variables need to be set in order for mlflow to work.  \n",
    "You might be able to live without the s3 and aws variables, but then log_artifact and log_model will probably not work.  \n",
    "The URI can be set to 127.0.0.1/localhost if training on the same machine as mlflow host.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bc07764ea2cfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T14:56:43.645467Z",
     "start_time": "2025-11-20T14:56:43.643417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000\n",
      "MLFLOW_S3_ENDPOINT_URL: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:9000\n",
      "AWS_ACCESS_KEY_ID: minio\n",
      "AWS_SECRET_ACCESS_KEY: minio123\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"MLFLOW_TRACKING_URI:\", os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "print(\"MLFLOW_S3_ENDPOINT_URL:\", os.environ.get(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(\"AWS_ACCESS_KEY_ID:\", os.environ.get(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(\"AWS_SECRET_ACCESS_KEY:\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))#%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d5033-a64f-4efa-be36-021137f69423",
   "metadata": {},
   "source": [
    "**Generic MLFLow Setup**\n",
    "Import it, then check the URI, if it matches, import and env variables are set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ae45a0-7e81-4e92-aca6-32093069b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412d058-9724-4dcd-8d4b-2f43414ba833",
   "metadata": {},
   "source": [
    "# Setting up an experiment\n",
    "Experiments are like directories, and can be used to group different runs together.  \n",
    "For example:  \n",
    "- a evaluation over different models with the same usecase.\n",
    "- different runs during prototyping of a model (Such as ARIMA)\n",
    "\n",
    "This can be done with the code below.  \n",
    "If the experiment does not exists, a new experiment will be created (so dont add for loops or cv params to the experiment name).  \n",
    "If you dont set an experiment, runs may just be added to the default experiment(if available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8b5136-4a5f-46e3-8fec-ea01ae9a0a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/7', creation_time=1763651138621, experiment_id='7', last_update_time=1763651138621, lifecycle_stage='active', name='MLFlow_Showcase', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"MLFlow_Showcase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a024d4-cc00-41f8-a987-8aeb3548c931",
   "metadata": {},
   "source": [
    "# Logging a run\n",
    "Runs are instances of a model training. \n",
    "For example, training a model is a single run, It does not matter how many epochs, as long as its just a single model to be trained, its a run.  \n",
    "If the model run is aborted or fails, and is then restarted, it will be a new run.  \n",
    "If the same playbook is executed after the run is completed, it will be a new run. \n",
    "Important: If the run is not stopped(visible in mlflow ui), there may be an error \"run is already active). Use try catch, or alternatively the \"with\" statement. \n",
    "\n",
    "If we do a gridsearch over different hyper parameters, each of them would be a new run. Thats what nested runs are for, we will see them later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfc886d-b542-4811-afce-c5fae86812ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run SimpleRun at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/18599df8ea7547a0a81035424fc3642b\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\") # setup experiment\n",
    "\n",
    "with mlflow.start_run(run_name=\"SimpleRun\"):\n",
    "    mlflow.log_param(key=\"UselessParam\", value=\"ThisValueIsUseles\")\n",
    "    # model training code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdddc19-274b-46db-84f7-762464331c0c",
   "metadata": {},
   "source": [
    "# Logging parameters, artifacts, figures, metrics.\n",
    "Logging in mlflow is done using the log_param, log_metrics, log_artifacts functions. See the training code below for samples.  \n",
    "check the docs for more log_XYZ functions, there are a lot of them, for example figures(matplotlib) can be logged as well. Or files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30c8e56-41f7-4f7e-b20a-22d7a0c71c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These need to be used when a run is already started using start_run\n",
    "mlflow.log_param(key=\"random_state\", value= \"42\")\n",
    "mlflow.log_metric(\"f1_score\", \"00324\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20708f-7ee9-4e7a-b1a3-33d47d32efb6",
   "metadata": {},
   "source": [
    "# Simple SK Learn Example \n",
    "Including setup, loggin params, logging metrics.  \n",
    "The model is also logged, it does make sense to not rely on mlflow for model storage though.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9e7ab0-2f3f-42b0-9b2b-75934a81feb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gentle-shrimp-213 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/869584cc398c4b3783356da24f891fbb\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 17:59:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 17:59:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 17:59:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ðŸƒ View run RandomForestClassifier at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/908650f89bda4ca384e8b5d726e16b69\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# this is only required because there may be already a run from above. This should not happen during \"normal\" coding\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\")\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"RandomForestClassifier\"):\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    n_estimators = 10\n",
    "    max_depth = 3\n",
    "    random_state = 42\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    \n",
    "    print(f\"Model trained successfully!\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a2299-68e0-4ff0-ad83-c917a7144eff",
   "metadata": {},
   "source": [
    "# Using nested runs. \n",
    "\n",
    "I use this mostly during grid search.  \n",
    "\n",
    "## The problem when not using them:\n",
    "Because every single time a new parameter is used, its technically a new model.  \n",
    "This leads us to having N runs, one for each parameter tested.  \n",
    "Will fill up storage quite quickly and will make it hard to filter for runs in the ui. \n",
    "\n",
    "\n",
    "## solution:  \n",
    "Nested runs let you organize all those parameter combinations under a single parent run.  \n",
    "Instead of having 50 separate runs cluttering your experiment, you get 1 parent run with 50 child runs inside it.  \n",
    "\n",
    "## How it works\n",
    "The parent run tracks the overall grid search.  \n",
    "Each child run tracks a specific parameter combination.  \n",
    "You mark child runs with nested=True when starting them.  \n",
    "\n",
    "## How it will look\n",
    "Storage is cleaner because runs are grouped hierarchically.  \n",
    "The UI shows an expandable tree structure instead of a flat list.  \n",
    "You can compare all variations in one place without filtering through unrelated runs.  \n",
    "The parent run stores summary info while children store detailed metrics.  \n",
    "\n",
    "## When to use\n",
    "Grid search and hyperparameter tuning is the obvious one.  \n",
    "Cross-validation where each fold is a child run.  \n",
    "Multi-stage pipelines where each stage gets its own nested run.  \n",
    "Ensemble methods with a parent for the ensemble and children for individual models.  \n",
    "\n",
    "\n",
    "# Notes about the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5084402-ac52-4988-b465-94302a5887aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search with 18 parameter combinations...\n",
      "\n",
      "[1/18] Training with params: {'n_estimators': 5, 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:02 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_1 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/c5e5f2438efa446180189f0c37875a42\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[2/18] Training with params: {'n_estimators': 5, 'max_depth': 2, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_2 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/02fdfe03b8d1448e929f528f0722fa57\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[3/18] Training with params: {'n_estimators': 5, 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_3 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/b85fab005581483393a442ae3790e120\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[4/18] Training with params: {'n_estimators': 5, 'max_depth': 3, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_4 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/4716c8412c9e40edbdfcbec477f2abc8\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[5/18] Training with params: {'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_5 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/737825f2c18d48b783944692d017fa91\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[6/18] Training with params: {'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:13 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_6 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/855471de5e2b4f459778965707fdd9f6\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[7/18] Training with params: {'n_estimators': 10, 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:15 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_7 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/b90188b509b04e99aea1fbec4823e7bb\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[8/18] Training with params: {'n_estimators': 10, 'max_depth': 2, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:17 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_8 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/8e4cce7d871e47a98479db78dfc0a84b\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[9/18] Training with params: {'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_9 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/5b61e1584ea1482e9f036243073c20d4\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[10/18] Training with params: {'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:22 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_10 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/53825ac4c16743dd8e4293aa0afcb159\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[11/18] Training with params: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:24 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_11 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/49be1d5f24804ebebd8b346127855ece\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[12/18] Training with params: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:26 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_12 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/1899d8ed40844818903cf37c453fd3a6\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[13/18] Training with params: {'n_estimators': 20, 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:29 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_13 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/c03fb5d88d204d2e9d5ce8e0e021dfcd\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[14/18] Training with params: {'n_estimators': 20, 'max_depth': 2, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_14 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/efc401aea91249c1b9d75a1b17e8afdb\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[15/18] Training with params: {'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_15 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/23e0116aefd740c3b7297f8e3f4803e0\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[16/18] Training with params: {'n_estimators': 20, 'max_depth': 3, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:35 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_16 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/04cbd192e5e1448e8e1af1b6eabc2528\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[17/18] Training with params: {'n_estimators': 20, 'max_depth': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:38 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_17 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/8372d1de1b5d4ac693ce68ae6ea03f9e\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n",
      "[18/18] Training with params: {'n_estimators': 20, 'max_depth': 5, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 18:02:40 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_18 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/8880f9a2e061485088969b03b7a061f3\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 5, 'max_depth': 2, 'min_samples_split': 2}\n",
      "Best accuracy: 1.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 18:02:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/11/20 18:02:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Grid search complete!\n",
      "==================================================\n",
      "ðŸƒ View run GridSearch_ParentRun at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8/runs/523a240fd3f64436b8e3defc8a26048d\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/8\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import itertools\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\")\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "param_combinations = [dict(zip(param_grid.keys(), v)) \n",
    "                      for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "print(f\"Running grid search with {len(param_combinations)} parameter combinations...\\n\")\n",
    "\n",
    "# Parent run for the entire grid search\n",
    "with mlflow.start_run(run_name=\"GridSearch_ParentRun\") as parent_run:\n",
    "    \n",
    "    # Log grid search configuration\n",
    "    mlflow.log_param(\"total_combinations\", len(param_combinations))\n",
    "    mlflow.log_param(\"param_grid\", str(param_grid))\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    all_results = []\n",
    "    \n",
    "    # Iterate through parameter combinations\n",
    "    for idx, params in enumerate(param_combinations, 1):\n",
    "        \n",
    "        # Nested child run for each parameter combination\n",
    "        with mlflow.start_run(run_name=f\"Run_{idx}\", nested=True):\n",
    "            \n",
    "            print(f\"[{idx}/{len(param_combinations)}] Training with params: {params}\")\n",
    "            \n",
    "            # Log parameters\n",
    "            for param_name, param_value in params.items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "            # Train model\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                max_depth=params['max_depth'],\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            precision = precision_score(y_test, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            \n",
    "            # Track results\n",
    "            all_results.append({\n",
    "                'params': params,\n",
    "                'accuracy': accuracy,\n",
    "                'f1_score': f1\n",
    "            })\n",
    "            \n",
    "            # Update best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = params\n",
    "            \n",
    "            print(f\"  â†’ Accuracy: {accuracy:.4f}, F1: {f1:.4f}\\n\")\n",
    "    \n",
    "    # Log best results to parent run\n",
    "    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "    mlflow.log_param(\"best_params\", str(best_params))\n",
    "    \n",
    "    # Train and log best model\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "    \n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "    \n",
    "    # Create and log summary artifact\n",
    "    summary = \"Grid Search Results\\n\" + \"=\"*50 + \"\\n\\n\"\n",
    "    summary += f\"Total combinations tested: {len(param_combinations)}\\n\"\n",
    "    summary += f\"Best accuracy: {best_accuracy:.4f}\\n\"\n",
    "    summary += f\"Best parameters: {best_params}\\n\\n\"\n",
    "    summary += \"All Results:\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    for i, result in enumerate(sorted(all_results, key=lambda x: x['accuracy'], reverse=True), 1):\n",
    "        summary += f\"{i}. Accuracy: {result['accuracy']:.4f} | Params: {result['params']}\\n\"\n",
    "    \n",
    "    with open(\"grid_search_summary.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    mlflow.log_artifact(\"grid_search_summary.txt\")   # this is one of the possibilities to log files. \n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Grid search complete!\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e5c2d8-f757-4779-98c4-324067d3a7bd",
   "metadata": {},
   "source": [
    "# What else is there?  \n",
    "\n",
    "In short: alot.  \n",
    "What else would be possible:  \n",
    "- write the entire train and test dataset to mlflow.\n",
    "- write an evaluation set, where mlflow server itself compares the models using the eval set (maybe not enabled in compose)\n",
    "\n",
    "The ways to waste time are nearly endless, and using every single feature will be a bit overkill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9b868-a167-4e34-8374-de6fe6753501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
