{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd647aefa1c750d",
   "metadata": {},
   "source": [
    "# Load environment variables.\n",
    "\n",
    "## These are used to configure the mlflow library. And should point to your mlflow instance.  \n",
    "### MLFLOW_TRACKING_URI\n",
    "this is the main mlflow server, same as where the webui runs.  \n",
    "Normally on port 5000\n",
    "### MLFLOW_S3_ENDPOINT_URL\n",
    "this is the S3/artifact store. Is a minio instance(see compose file).  \n",
    "It is required because the mlflow client will push artifacts directly to the s3 store, not the main mlflow api.  \n",
    "Default runs on port 9000\n",
    "\n",
    "\n",
    "This example uses jupyter magicks to import the .env file.  \n",
    "Be careful, the .env for the docker-compose and the .env for the project are treated separately, and this should be the .env from the project root.  \n",
    "\n",
    "**Magicks for notebooks:** "
   ]
  },
  {
   "cell_type": "code",
   "id": "f8877339b4e793bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:33.963318Z",
     "start_time": "2025-11-30T12:51:33.957434Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%reload_ext dotenv\n",
    "%dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "982c0f0a6a03bc79",
   "metadata": {},
   "source": [
    "**Or dotenv for normal python**"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b0c85c8e0ec5113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:36.962959Z",
     "start_time": "2025-11-30T12:51:36.957627Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "7f98756338b9fb7a",
   "metadata": {},
   "source": [
    "**Required env variables**  \n",
    "These environment variables need to be set in order for mlflow to work.  \n",
    "You might be able to live without the s3 and aws variables, but then log_artifact and log_model will probably not work.  \n",
    "The URI can be set to 127.0.0.1/localhost if training on the same machine as mlflow host.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "25bc07764ea2cfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:38.002059Z",
     "start_time": "2025-11-30T12:51:37.999289Z"
    }
   },
   "source": [
    "import os\n",
    "print(\"MLFLOW_TRACKING_URI:\", os.environ.get(\"MLFLOW_TRACKING_URI\"))\n",
    "print(\"MLFLOW_S3_ENDPOINT_URL:\", os.environ.get(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(\"AWS_ACCESS_KEY_ID:\", os.environ.get(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(\"AWS_SECRET_ACCESS_KEY:\", os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))#%%\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000\n",
      "MLFLOW_S3_ENDPOINT_URL: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:9000\n",
      "AWS_ACCESS_KEY_ID: minio\n",
      "AWS_SECRET_ACCESS_KEY: minio123\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "765d5033-a64f-4efa-be36-021137f69423",
   "metadata": {},
   "source": [
    "**Generic MLFLow Setup**\n",
    "Import it, then check the URI, if it matches, import and env variables are set. "
   ]
  },
  {
   "cell_type": "code",
   "id": "e1ae45a0-7e81-4e92-aca6-32093069b2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:40.517803Z",
     "start_time": "2025-11-30T12:51:40.022974Z"
    }
   },
   "source": [
    "import mlflow\n",
    "print(mlflow.get_tracking_uri())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "4412d058-9724-4dcd-8d4b-2f43414ba833",
   "metadata": {},
   "source": [
    "# Setting up an experiment\n",
    "Experiments are like directories, and can be used to group different runs together.  \n",
    "For example:  \n",
    "- a evaluation over different models with the same usecase.\n",
    "- different runs during prototyping of a model (Such as ARIMA)\n",
    "\n",
    "This can be done with the code below.  \n",
    "If the experiment does not exists, a new experiment will be created (so dont add for loops or cv params to the experiment name).  \n",
    "If you dont set an experiment, runs may just be added to the default experiment(if available)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc8b5136-4a5f-46e3-8fec-ea01ae9a0a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:42.899060Z",
     "start_time": "2025-11-30T12:51:42.583542Z"
    }
   },
   "source": [
    "mlflow.set_experiment(experiment_name=\"MLFlow_Showcase\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/1', creation_time=1764506916586, experiment_id='1', last_update_time=1764506916586, lifecycle_stage='active', name='MLFlow_Showcase', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c7a024d4-cc00-41f8-a987-8aeb3548c931",
   "metadata": {},
   "source": [
    "# Logging a run\n",
    "Runs are instances of a model training. \n",
    "For example, training a model is a single run, It does not matter how many epochs, as long as its just a single model to be trained, its a run.  \n",
    "If the model run is aborted or fails, and is then restarted, it will be a new run.  \n",
    "If the same playbook is executed after the run is completed, it will be a new run. \n",
    "Important: If the run is not stopped(visible in mlflow ui), there may be an error \"run is already active). Use try catch, or alternatively the \"with\" statement. \n",
    "\n",
    "If we do a gridsearch over different hyper parameters, each of them would be a new run. Thats what nested runs are for, we will see them later. \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7cfc886d-b542-4811-afce-c5fae86812ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:44.706878Z",
     "start_time": "2025-11-30T12:51:44.447103Z"
    }
   },
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\") # setup experiment\n",
    "\n",
    "with mlflow.start_run(run_name=\"SimpleRun\"):\n",
    "    mlflow.log_param(key=\"UselessParam\", value=\"ThisValueIsUseles\")\n",
    "    # model training code\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run SimpleRun at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/193620decc0f437e93515cc0639d327c\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "dfdddc19-274b-46db-84f7-762464331c0c",
   "metadata": {},
   "source": [
    "# Logging parameters, artifacts, figures, metrics.\n",
    "Logging in mlflow is done using the log_param, log_metrics, log_artifacts functions. See the training code below for samples.  \n",
    "check the docs for more log_XYZ functions, there are a lot of them, for example figures(matplotlib) can be logged as well. Or files.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f30c8e56-41f7-4f7e-b20a-22d7a0c71c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:44.907208Z",
     "start_time": "2025-11-30T12:51:44.783375Z"
    }
   },
   "source": [
    "# These need to be used when a run is already started using start_run\n",
    "mlflow.log_param(key=\"random_state\", value= \"42\")\n",
    "mlflow.log_metric(\"f1_score\", \"00324\")\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "ea20708f-7ee9-4e7a-b1a3-33d47d32efb6",
   "metadata": {},
   "source": [
    "# Simple SK Learn Example \n",
    "Including setup, loggin params, logging metrics.  \n",
    "The model is also logged, it does make sense to not rely on mlflow for model storage though.  "
   ]
  },
  {
   "cell_type": "code",
   "id": "da9e7ab0-2f3f-42b0-9b2b-75934a81feb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:51:48.124922Z",
     "start_time": "2025-11-30T12:51:45.117837Z"
    }
   },
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# this is only required because there may be already a run from above. This should not happen during \"normal\" coding\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\")\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"RandomForestClassifier\"):\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    n_estimators = 10\n",
    "    max_depth = 3\n",
    "    random_state = 42\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    \n",
    "    print(f\"Model trained successfully!\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run beautiful-snail-350 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/8fc8eb6fc9e243febaf5b986245760f3\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:47 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ðŸƒ View run RandomForestClassifier at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/f3e81e2244094b1e932b3a3d799ddcdd\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "333a2299-68e0-4ff0-ad83-c917a7144eff",
   "metadata": {},
   "source": [
    "# Using nested runs. \n",
    "\n",
    "I use this mostly during grid search.  \n",
    "\n",
    "## The problem when not using them:\n",
    "Because every single time a new parameter is used, its technically a new model.  \n",
    "This leads us to having N runs, one for each parameter tested.  \n",
    "Will fill up storage quite quickly and will make it hard to filter for runs in the ui. \n",
    "\n",
    "\n",
    "## solution:  \n",
    "Nested runs let you organize all those parameter combinations under a single parent run.  \n",
    "Instead of having 50 separate runs cluttering your experiment, you get 1 parent run with 50 child runs inside it.  \n",
    "\n",
    "## How it works\n",
    "The parent run tracks the overall grid search.  \n",
    "Each child run tracks a specific parameter combination.  \n",
    "You mark child runs with nested=True when starting them.  \n",
    "\n",
    "## How it will look\n",
    "Storage is cleaner because runs are grouped hierarchically.  \n",
    "The UI shows an expandable tree structure instead of a flat list.  \n",
    "You can compare all variations in one place without filtering through unrelated runs.  \n",
    "The parent run stores summary info while children store detailed metrics.  \n",
    "\n",
    "## When to use\n",
    "Grid search and hyperparameter tuning is the obvious one.  \n",
    "Cross-validation where each fold is a child run.  \n",
    "Multi-stage pipelines where each stage gets its own nested run.  \n",
    "Ensemble methods with a parent for the ensemble and children for individual models.  \n",
    "\n",
    "\n",
    "# Notes about the cell below"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5084402-ac52-4988-b465-94302a5887aa",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T12:52:10.896019Z",
     "start_time": "2025-11-30T12:51:48.175747Z"
    }
   },
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import itertools\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment(experiment_name=\"MLFlow_ExperimentWithRuns\")\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "param_combinations = [dict(zip(param_grid.keys(), v)) \n",
    "                      for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "print(f\"Running grid search with {len(param_combinations)} parameter combinations...\\n\")\n",
    "\n",
    "# Parent run for the entire grid search\n",
    "with mlflow.start_run(run_name=\"GridSearch_ParentRun\") as parent_run:\n",
    "    \n",
    "    # Log grid search configuration\n",
    "    mlflow.log_param(\"total_combinations\", len(param_combinations))\n",
    "    mlflow.log_param(\"param_grid\", str(param_grid))\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "    all_results = []\n",
    "    \n",
    "    # Iterate through parameter combinations\n",
    "    for idx, params in enumerate(param_combinations, 1):\n",
    "        \n",
    "        # Nested child run for each parameter combination\n",
    "        with mlflow.start_run(run_name=f\"Run_{idx}\", nested=True):\n",
    "            \n",
    "            print(f\"[{idx}/{len(param_combinations)}] Training with params: {params}\")\n",
    "            \n",
    "            # Log parameters\n",
    "            for param_name, param_value in params.items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "            # Train model\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                max_depth=params['max_depth'],\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            precision = precision_score(y_test, y_pred, average='weighted')\n",
    "            recall = recall_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            \n",
    "            # Track results\n",
    "            all_results.append({\n",
    "                'params': params,\n",
    "                'accuracy': accuracy,\n",
    "                'f1_score': f1\n",
    "            })\n",
    "            \n",
    "            # Update best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = params\n",
    "            \n",
    "            print(f\"  â†’ Accuracy: {accuracy:.4f}, F1: {f1:.4f}\\n\")\n",
    "    \n",
    "    # Log best results to parent run\n",
    "    mlflow.log_metric(\"best_accuracy\", best_accuracy)\n",
    "    mlflow.log_param(\"best_params\", str(best_params))\n",
    "    \n",
    "    # Train and log best model\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "    \n",
    "    best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "    \n",
    "    # Create and log summary artifact\n",
    "    summary = \"Grid Search Results\\n\" + \"=\"*50 + \"\\n\\n\"\n",
    "    summary += f\"Total combinations tested: {len(param_combinations)}\\n\"\n",
    "    summary += f\"Best accuracy: {best_accuracy:.4f}\\n\"\n",
    "    summary += f\"Best parameters: {best_params}\\n\\n\"\n",
    "    summary += \"All Results:\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    for i, result in enumerate(sorted(all_results, key=lambda x: x['accuracy'], reverse=True), 1):\n",
    "        summary += f\"{i}. Accuracy: {result['accuracy']:.4f} | Params: {result['params']}\\n\"\n",
    "    \n",
    "    with open(\"grid_search_summary.txt\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    mlflow.log_artifact(\"grid_search_summary.txt\")   # this is one of the possibilities to log files. \n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Grid search complete!\")\n",
    "    print(\"=\"*50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search with 18 parameter combinations...\n",
      "\n",
      "[1/18] Training with params: {'n_estimators': 5, 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_1 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/f0272704bc404d55a0597e1b20c51185\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[2/18] Training with params: {'n_estimators': 5, 'max_depth': 2, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:52 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_2 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/80e3add7572e4c7398f327b715bcd711\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[3/18] Training with params: {'n_estimators': 5, 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_3 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/c848f51972854657821ddd501b9bcbcb\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[4/18] Training with params: {'n_estimators': 5, 'max_depth': 3, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:56 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_4 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/4890923c01c74213a3e7633a97b3bbea\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[5/18] Training with params: {'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:51:58 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:51:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_5 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/87d527255a274a87be6756ef3f5e5969\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[6/18] Training with params: {'n_estimators': 5, 'max_depth': 5, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:51:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:00 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 0.9667, F1: 0.9668\n",
      "\n",
      "ðŸƒ View run Run_6 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/a24589370ecd4fc59b2ff8c050f1b9f7\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[7/18] Training with params: {'n_estimators': 10, 'max_depth': 2, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:52:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_7 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/3f863711c38c44e89ea90f2014ec043a\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[8/18] Training with params: {'n_estimators': 10, 'max_depth': 2, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:52:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:03 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_8 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/d684b95741a04d51a79fe981a906329d\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[9/18] Training with params: {'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:52:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:05 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_9 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/81ceeb6d47c741c9b99d3178d502fa68\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[10/18] Training with params: {'n_estimators': 10, 'max_depth': 3, 'min_samples_split': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:52:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_10 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/872f038ba8a04be28db6a72a67d5c239\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "[11/18] Training with params: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 13:52:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 13:52:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001B[31m2025/11/30 13:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â†’ Accuracy: 1.0000, F1: 1.0000\n",
      "\n",
      "ðŸƒ View run Run_11 at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/69c309f7ce6f457fae75f8041dab3124\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n",
      "ðŸƒ View run GridSearch_ParentRun at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2/runs/bbf829150ada48828e80398919bc9caa\n",
      "ðŸ§ª View experiment at: http://lukas-hp-z2-mini-g1a-workstation-desktop-pc.tail7adb49.ts.net:5000/#/experiments/2\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: The run bbf829150ada48828e80398919bc9caa must be in the 'active' state. Current state is deleted.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRestException\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 46\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, params \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(param_combinations, \u001B[32m1\u001B[39m):\n\u001B[32m     44\u001B[39m \n\u001B[32m     45\u001B[39m     \u001B[38;5;66;03m# Nested child run for each parameter combination\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mRun_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43midx\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnested\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m[\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43midx\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparam_combinations\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m] Training with params: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mparams\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:260\u001B[39m, in \u001B[36mActiveRun.__exit__\u001B[39m\u001B[34m(self, exc_type, exc_val, exc_tb)\u001B[39m\n\u001B[32m    259\u001B[39m     status = RunStatus.FINISHED \u001B[38;5;28;01mif\u001B[39;00m exc_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m RunStatus.FAILED\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m     \u001B[43mend_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunStatus\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m exc_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:551\u001B[39m, in \u001B[36mend_run\u001B[39m\u001B[34m(status)\u001B[39m\n\u001B[32m    550\u001B[39m _last_active_run_id.set(last_active_run_id)\n\u001B[32m--> \u001B[39m\u001B[32m551\u001B[39m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlast_active_run_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    552\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m last_active_run_id \u001B[38;5;129;01min\u001B[39;00m run_id_to_system_metrics_monitor:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:3498\u001B[39m, in \u001B[36mMlflowClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m   3456\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Set a run's status to terminated.\u001B[39;00m\n\u001B[32m   3457\u001B[39m \n\u001B[32m   3458\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   3496\u001B[39m \n\u001B[32m   3497\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3498\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tracking_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:797\u001B[39m, in \u001B[36mTrackingServiceClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m    796\u001B[39m \u001B[38;5;28mself\u001B[39m._log_url(run_id)\n\u001B[32m--> \u001B[39m\u001B[32m797\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate_run_info\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    799\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_status\u001B[49m\u001B[43m=\u001B[49m\u001B[43mRunStatus\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    800\u001B[39m \u001B[43m    \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m=\u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    801\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:311\u001B[39m, in \u001B[36mRestStore.update_run_info\u001B[39m\u001B[34m(self, run_id, run_status, end_time, run_name)\u001B[39m\n\u001B[32m    302\u001B[39m req_body = message_to_json(\n\u001B[32m    303\u001B[39m     UpdateRun(\n\u001B[32m    304\u001B[39m         run_uuid=run_id,\n\u001B[32m   (...)\u001B[39m\u001B[32m    309\u001B[39m     )\n\u001B[32m    310\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m311\u001B[39m response_proto = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mUpdateRun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq_body\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m RunInfo.from_proto(response_proto.run_info)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:203\u001B[39m, in \u001B[36mRestStore._call_endpoint\u001B[39m\u001B[34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001B[39m\n\u001B[32m    202\u001B[39m response_proto = response_proto \u001B[38;5;129;01mor\u001B[39;00m api.Response()\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_endpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_host_creds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    206\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjson_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretry_timeout_seconds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_timeout_seconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:596\u001B[39m, in \u001B[36mcall_endpoint\u001B[39m\u001B[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[39m\n\u001B[32m    594\u001B[39m     response = http_request(**call_kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m596\u001B[39m response = \u001B[43mverify_rest_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    597\u001B[39m response_to_parse = response.text\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:315\u001B[39m, in \u001B[36mverify_rest_response\u001B[39m\u001B[34m(response, endpoint)\u001B[39m\n\u001B[32m    314\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response.text):\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m RestException(json.loads(response.text))\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mRestException\u001B[39m: INVALID_PARAMETER_VALUE: The run 69c309f7ce6f457fae75f8041dab3124 must be in the 'active' state. Current state is deleted.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mRestException\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 32\u001B[39m\n\u001B[32m     29\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mRunning grid search with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(param_combinations)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m parameter combinations...\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m# Parent run for the entire grid search\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m \u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mGridSearch_ParentRun\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mas\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mparent_run\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     33\u001B[39m \n\u001B[32m     34\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Log grid search configuration\u001B[39;49;00m\n\u001B[32m     35\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtotal_combinations\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparam_combinations\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_param\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparam_grid\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:260\u001B[39m, in \u001B[36mActiveRun.__exit__\u001B[39m\u001B[34m(self, exc_type, exc_val, exc_tb)\u001B[39m\n\u001B[32m    258\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(r.info.run_id == \u001B[38;5;28mself\u001B[39m.info.run_id \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m active_run_stack):\n\u001B[32m    259\u001B[39m     status = RunStatus.FINISHED \u001B[38;5;28;01mif\u001B[39;00m exc_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m RunStatus.FAILED\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m     \u001B[43mend_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunStatus\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m exc_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:551\u001B[39m, in \u001B[36mend_run\u001B[39m\u001B[34m(status)\u001B[39m\n\u001B[32m    549\u001B[39m last_active_run_id = run.info.run_id\n\u001B[32m    550\u001B[39m _last_active_run_id.set(last_active_run_id)\n\u001B[32m--> \u001B[39m\u001B[32m551\u001B[39m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlast_active_run_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    552\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m last_active_run_id \u001B[38;5;129;01min\u001B[39;00m run_id_to_system_metrics_monitor:\n\u001B[32m    553\u001B[39m     system_metrics_monitor = run_id_to_system_metrics_monitor.pop(last_active_run_id)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:3498\u001B[39m, in \u001B[36mMlflowClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m   3453\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mset_terminated\u001B[39m(\n\u001B[32m   3454\u001B[39m     \u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, status: \u001B[38;5;28mstr\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m, end_time: \u001B[38;5;28mint\u001B[39m | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3455\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3456\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Set a run's status to terminated.\u001B[39;00m\n\u001B[32m   3457\u001B[39m \n\u001B[32m   3458\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   3496\u001B[39m \n\u001B[32m   3497\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3498\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tracking_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_terminated\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:797\u001B[39m, in \u001B[36mTrackingServiceClient.set_terminated\u001B[39m\u001B[34m(self, run_id, status, end_time)\u001B[39m\n\u001B[32m    795\u001B[39m \u001B[38;5;28mself\u001B[39m.store.shut_down_async_logging()\n\u001B[32m    796\u001B[39m \u001B[38;5;28mself\u001B[39m._log_url(run_id)\n\u001B[32m--> \u001B[39m\u001B[32m797\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate_run_info\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    799\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_status\u001B[49m\u001B[43m=\u001B[49m\u001B[43mRunStatus\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatus\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    800\u001B[39m \u001B[43m    \u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m=\u001B[49m\u001B[43mend_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    801\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:311\u001B[39m, in \u001B[36mRestStore.update_run_info\u001B[39m\u001B[34m(self, run_id, run_status, end_time, run_name)\u001B[39m\n\u001B[32m    301\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Updates the metadata of the specified run.\"\"\"\u001B[39;00m\n\u001B[32m    302\u001B[39m req_body = message_to_json(\n\u001B[32m    303\u001B[39m     UpdateRun(\n\u001B[32m    304\u001B[39m         run_uuid=run_id,\n\u001B[32m   (...)\u001B[39m\u001B[32m    309\u001B[39m     )\n\u001B[32m    310\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m311\u001B[39m response_proto = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mUpdateRun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq_body\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m RunInfo.from_proto(response_proto.run_info)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/store/tracking/rest_store.py:203\u001B[39m, in \u001B[36mRestStore._call_endpoint\u001B[39m\u001B[34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001B[39m\n\u001B[32m    201\u001B[39m     endpoint, method = \u001B[38;5;28mself\u001B[39m._METHOD_TO_INFO[api]\n\u001B[32m    202\u001B[39m response_proto = response_proto \u001B[38;5;129;01mor\u001B[39;00m api.Response()\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_endpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_host_creds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m    \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    206\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjson_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_proto\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretry_timeout_seconds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_timeout_seconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:596\u001B[39m, in \u001B[36mcall_endpoint\u001B[39m\u001B[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[39m\n\u001B[32m    593\u001B[39m     call_kwargs[\u001B[33m\"\u001B[39m\u001B[33mjson\u001B[39m\u001B[33m\"\u001B[39m] = json_body\n\u001B[32m    594\u001B[39m     response = http_request(**call_kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m596\u001B[39m response = \u001B[43mverify_rest_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    597\u001B[39m response_to_parse = response.text\n\u001B[32m    598\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Github/casml4se-stonkswagen/.venv/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:315\u001B[39m, in \u001B[36mverify_rest_response\u001B[39m\u001B[34m(response, endpoint)\u001B[39m\n\u001B[32m    313\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m response.status_code != \u001B[32m200\u001B[39m:\n\u001B[32m    314\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response.text):\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m RestException(json.loads(response.text))\n\u001B[32m    316\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    317\u001B[39m         base_msg = (\n\u001B[32m    318\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    319\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse.status_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m != 200\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    320\u001B[39m         )\n",
      "\u001B[31mRestException\u001B[39m: INVALID_PARAMETER_VALUE: The run bbf829150ada48828e80398919bc9caa must be in the 'active' state. Current state is deleted."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "77e5c2d8-f757-4779-98c4-324067d3a7bd",
   "metadata": {},
   "source": [
    "# What else is there?  \n",
    "\n",
    "In short: alot.  \n",
    "What else would be possible:  \n",
    "- write the entire train and test dataset to mlflow.\n",
    "- write an evaluation set, where mlflow server itself compares the models using the eval set (maybe not enabled in compose)\n",
    "\n",
    "The ways to waste time are nearly endless, and using every single feature will be a bit overkill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9b868-a167-4e34-8374-de6fe6753501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a3788d5af390c72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
