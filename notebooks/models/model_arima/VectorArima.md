
# Vector ARIMA (VARIMA)
Multivariate extension of ARIMA for jointly modeling several time series with autoregressive (AR), differencing/integration (I), and moving-average (MA) dynamics and their cross-dependencies.

Related reading:
- Vector autoregression (VAR): https://en.wikipedia.org/wiki/Vector_autoregression
- VARMA/VARIMA overview: https://www.statsmodels.org/stable/tsa.html

# BELOW THIS LINE AUTOGENERATED WITH CLAUDE
-$-----------------------------------
## Model Explanation

VARIMA generalizes univariate ARIMA to a vector of series, allowing each series to depend not only on its own lags and errors but also on the lags and errors of the other series. This captures cross-series dynamics such as spillovers, co-movements, and lead–lag effects.

### What does it try to do?
It models the joint temporal structure of a k-dimensional time series `y_t = [y_{1,t}, ..., y_{k,t}]ᵀ`, producing coherent multivariate forecasts that account for both within-series autocorrelation and cross-series interactions.

### How does it work?
At a high level, a VARIMA(p, d, q) for the vector `y_t` applies differencing (integration) and then fits a VARMA(p, q) to the differenced series:

1. Integration (optional): difference one or more times to achieve (vector) stationarity
   - First difference: `Δ y_t = y_t − y_{t−1}`
   - Seasonal and component-wise differencing are possible; orders may be common or per-series

2. VARMA on differenced data:
   - AR part: past values of all series affect current values
   - MA part: past shocks/innovations of all series affect current values

A compact representation (using the lag operator L) is:
```
Φ(L) (1 − L)^d y_t = c + Θ(L) ε_t
```
- `Φ(L) = I − Φ₁ L − ... − Φ_p L^p` where each `Φ_i` is k×k (cross-lag coefficients)
- `Θ(L) = I + Θ₁ L + ... + Θ_q L^q` where each `Θ_i` is k×k (cross-innovation coefficients)
- `ε_t` is a k-dimensional white noise with covariance matrix Σ_ε

### What is the output?
- Multivariate point forecasts for each horizon and each series
- Forecast error covariance matrices, enabling:
  - Per-series prediction intervals
  - Joint prediction regions (ellipsoids) and correlated uncertainty across series

## Parameters/Hyperparameters

### Core Orders (p, d, q)
- **p (VAR order)**: number of autoregressive lags shared across all series
- **d (integration order)**: number of differences required for (vector) stationarity; can be common or per-series
- **q (VMA order)**: number of moving-average lags of the innovations

Typical practical ranges (problem-dependent):
- p: 0–5
- d: 0–2
- q: 0–5

### Additional Settings
- **Intercept/constant and deterministic trend**: include `c`, and optionally linear trend or seasonal dummies
- **Exogenous regressors (VARIMAX)**: external predictors `X_t` affecting the vector `y_t`
- **Constraints/regularization**: ridge/LASSO penalties or Bayesian priors to mitigate parameter explosion for large k, p, q
- **Common vs per-series differencing**: decide whether all series use the same d or individual d_i
- **Seasonality**: seasonal differencing and seasonal VARMA terms (less common; many workflows prefer seasonal dummies)

### How to select orders
1. Stationarity/Integration (d):
   - Unit-root tests per series (ADF, KPSS) and cointegration tests (Johansen) to decide differencing vs VECM
   - If series are cointegrated, a VECM (error-correction) may be preferable to plain VARIMA

2. Lag orders (p, q):
   - Information criteria on candidate models (AIC, BIC); for q>0 use VARMA/VARMAX if available
   - Start with VAR(p) on differenced data (q=0) and expand only if justified; VARMA can be hard to estimate reliably

3. Cross-validation:
   - Time-series CV (rolling/expanding window) on multivariate error metrics (e.g., average RMSE, energy distance)

## Outputs

### Forecasts
- Per-horizon per-series point forecasts
- Prediction intervals per series and joint covariance/elliptical regions
- Scenario/conditional forecasts if exogenous variables or conditioning paths are provided

### Model Diagnostics
- Residual analysis for each series and cross-correlations between residuals
- Multivariate Portmanteau tests (e.g., Ljung–Box/Box–Pierce generalizations)
- Stability: eigenvalues of companion matrix within the unit circle
- Forecast evaluation: multivariate accuracy metrics and calibration of joint intervals

### Model Statistics
- Log-likelihood, AIC/BIC
- Coefficient matrices `Φ_i` and `Θ_i` with standard errors
- Innovation covariance matrix Σ_ε

## Assumptions and Requirements

### Assumptions
1. (Vector) stationarity after differencing (if needed)
2. Linear relationships across series and lags
3. Innovations are zero-mean, serially uncorrelated, with constant covariance
4. Stability/invertibility conditions hold for AR and MA polynomials

### Requirements
- Sufficient sample size relative to parameters: with k series and p AR lags, parameter count grows ~k²p (and similarly for q)
- Regular sampling, minimal missingness (or appropriate imputation)
- Consider domain knowledge for identification and reasonable lag lengths

## Advantages and Limitations

### Advantages
- Captures cross-series dynamics and spillover effects
- Joint forecasting and coherent uncertainty quantification across series
- Interpretable lagged relationships; supports causality analysis (e.g., Granger tests)

### Limitations
- Parameter explosion and risk of overfitting for large k and/or large p, q
- VARMA/VARIMA estimation can be numerically challenging; software support is limited compared to univariate ARIMA
- Sensitive to nonstationarity and structural breaks; cointegration requires specialized treatment (VECM)

## Common Use Cases
- Macro/financial systems: jointly forecasting inflation, interest rates, GDP; multi-asset returns/volumes
- Demand forecasting across products/regions with interactions and cannibalization
- Multi-sensor/IoT signals with coupled dynamics
- Power systems and energy markets (load, price, renewables)

## Practical Implementation Notes
- In Python/statsmodels:
  - `VAR` models VAR(p). To approximate VARIMA(d), difference the data then fit VAR(p).
  - `VARMAX` estimates VARMA/VARMAX; true VARIMA support is limited—again, difference first.
  - For cointegrated nonstationary series, prefer `VECM` (error-correction) over plain differencing.
- Order selection via `select_order` for VAR (AIC/BIC/HQIC/FPPE), then assess need for MA terms.
- Always validate residuals (serial correlation and cross-correlation) and check stability.

## Extensions and Variations
- **VAR**: pure autoregressive vector model (q=0)
- **VARMA**: vector ARMA without integration (d=0)
- **VARIMAX**: VARIMA with exogenous regressors
- **VECM**: vector error-correction model for cointegrated systems (alternative to differencing)
- **Bayesian/regularized VAR/VARMA**: shrinkage for high-dimensional settings