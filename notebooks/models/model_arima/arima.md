
# ARIMA
ARIMA (Autoregressive Integrated Moving Average)
https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average

# BELOW THIS LINE AUTOGENERATED WITH CLAUDE
-$-----------------------------------
## Model Explanation

ARIMA is a statistical time series forecasting model that predicts future values based on past observations. It's one of the most widely used methods for time series analysis and forecasting.

### What does it try to do?
ARIMA attempts to capture and model the temporal dependencies in time series data to make predictions about future values. It's particularly effective for data that shows patterns over time, such as trends and seasonality (when combined with seasonal extensions).

### How does it work?
ARIMA combines three components:

1. **AR (Autoregressive)**: Uses past values to predict future values. The model assumes that past values have a **linear** effect on current values.
   - Formula: `y_t = c + φ₁y_{t-1} + φ₂y_{t-2} + ... + φ_p*y_{t-p} + ε_t`

2. **I (Integrated)**: Applies differencing to make the time series stationary (constant mean and variance over time). Differencing is the process of subtracting previous observations from current observations.
   - First difference: `y'_t = y_t - y_{t-1}`

3. **MA (Moving Average)**: Uses past forecast errors in a regression-like model to improve predictions.
   - Formula: `y_t = μ + ε_t + θ₁ε_{t-1} + θ₂ε_{t-2} + ... + θ_q*ε_{t-q}`

The complete ARIMA model is denoted as **ARIMA(p, d, q)** where:
- p = order of the autoregressive component
- d = degree of differencing
- q = order of the moving average component

### What is the output?
The output is **linear** in nature. ARIMA produces point forecasts along with confidence intervals for future time periods. The predictions are continuous numerical values that follow the same scale as the input data.

## Parameters/Hyperparameters

### Core Parameters (p, d, q)
- **p (AR order)**: Number of lag observations included in the model (autoregressive terms)
  - Higher values capture longer-term dependencies
  - Typical range: 0-5
  
- **d (Differencing order)**: Number of times the data needs to be differenced to achieve stationarity
  - d=0: No differencing (data is already stationary)
  - d=1: First difference (most common, removes linear trends)
  - d=2: Second difference (removes quadratic trends)
  - Typical range: 0-2

- **q (MA order)**: Number of lagged forecast errors in the prediction equation
  - Captures short-term irregularities
  - Typical range: 0-5

### Additional Parameters
- **constant/intercept**: Whether to include a constant term in the model
- **seasonal**: For seasonal ARIMA (SARIMA), additional parameters (P, D, Q, s) where s is the seasonal period
- **trend**: Type of trend component (none, constant, linear, quadratic)

### How to Select Parameters
1. **Visual inspection**: Plot ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Function)
   - PACF helps identify p (cuts off after lag p)
   - ACF helps identify q (cuts off after lag q)
   
2. **Statistical tests**: 
   - Augmented Dickey-Fuller test for stationarity (determines d)
   
3. **Information criteria**: 
   - AIC (Akaike Information Criterion)
   - BIC (Bayesian Information Criterion)
   - Lower values indicate better model fit

4. **Auto ARIMA**: Automated grid search algorithms that test combinations and select optimal parameters

## Outputs

### Forecasts
- **Point predictions**: Single best estimate for each future time step
- **Prediction intervals**: Confidence bands (typically 95% or 99%) showing uncertainty
- Intervals widen as forecast horizon increases (reflecting greater uncertainty)

### Model Diagnostics
- **Fitted values**: Model's predictions for historical data points
- **Residuals**: Difference between actual and fitted values
  - Should resemble white noise (random, normally distributed, constant variance)
  
### Model Statistics
- **AIC/BIC**: Model fit metrics for comparison
- **Log-likelihood**: Measure of how well the model fits the data
- **Coefficients**: Values for AR and MA terms with standard errors and p-values
- **Residual statistics**: Mean, variance, and statistical tests (Ljung-Box test for autocorrelation)

## Assumptions and Requirements

### Assumptions
1. **Stationarity**: The time series should be stationary (after differencing)
   - Constant mean over time
   - Constant variance over time
   - No seasonality (or handled separately)

2. **Linear relationships**: ARIMA assumes linear dependencies between observations

3. **Residuals**: Should be uncorrelated and normally distributed with zero mean

### Requirements
- **Sufficient data**: Typically need at least 50-100 observations for reliable estimates
- **No missing values**: Data should be complete and regularly spaced
- **Univariate**: Standard ARIMA models work with single time series (extensions exist for multivariate cases)

## Advantages and Limitations

### Advantages
- Well-established statistical foundation with interpretable parameters
- Effective for short to medium-term forecasting
- Handles trends and some patterns well
- Provides prediction intervals (uncertainty quantification)
- Works well with limited data compared to deep learning methods

### Limitations
- Assumes linear relationships (cannot capture complex nonlinear patterns)
- Requires stationarity (may need transformations)
- Struggles with long-term forecasts
- Basic ARIMA doesn't handle seasonality (need SARIMA extension)
- Manual parameter selection can be time-consuming
- Sensitive to outliers

## Common Use Cases
- Economic forecasting (GDP, inflation, unemployment)
- Stock price prediction
- Sales forecasting
- Weather prediction
- Demand forecasting
- Energy consumption prediction
- Website traffic analysis

## Extensions and Variations
- **SARIMA**: Seasonal ARIMA for data with seasonal patterns
- **ARIMAX**: ARIMA with exogenous variables (external predictors)
- **Vector ARIMA (VARIMA)**: Multivariate extension
- **Fractional ARIMA**: For long-memory processes