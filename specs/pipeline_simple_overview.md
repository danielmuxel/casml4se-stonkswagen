# Pipeline Ãœbersicht: Von Daten zum Forecast

## ðŸŽ¯ Die 6 Schritte (Einfach)

```mermaid
flowchart LR
    subgraph S1["1ï¸âƒ£ DATEN"]
        A1[("ðŸ—„ï¸ PostgreSQL")]
    end
    
    subgraph S2["2ï¸âƒ£ LADEN"]
        A2["ðŸ“¥ get_prices()"]
    end
    
    subgraph S3["3ï¸âƒ£ TRANSFORM"]
        A3["ðŸ”„ â†’ TimeSeries"]
    end
    
    subgraph S4["4ï¸âƒ£ TRAINING"]
        A4["ðŸŽ“ model.fit()"]
    end
    
    subgraph S5["5ï¸âƒ£ FORECAST"]
        A5["ðŸ”® model.predict()"]
    end
    
    subgraph S6["6ï¸âƒ£ AUSWERTEN"]
        A6["ðŸ“Š Metriken"]
    end
    
    S1 --> S2 --> S3 --> S4 --> S5 --> S6
    
    style S1 fill:#e3f2fd
    style S2 fill:#fff3e0
    style S3 fill:#f3e5f5
    style S4 fill:#e8f5e9
    style S5 fill:#fff9c4
    style S6 fill:#fce4ec
```

---

## ðŸ“‹ Detail pro Schritt

### 1ï¸âƒ£ DATEN (PostgreSQL)

**Was haben wir:**
| Tabelle | Beschreibung | Intervall |
|---------|--------------|-----------|
| `prices` | Aktuelle GW2 TP Preise | ~5 Min |
| `gw2bltc_historical_prices` | Historische Daten (BLTC) | variabel |
| `gw2tp_historical_prices` | Historische Daten (TP) | variabel |

**Spalten (prices):**
```
item_id, buy_unit_price, sell_unit_price, buy_quantity, sell_quantity, fetched_at
```

---

### 2ï¸âƒ£ LADEN (Data Retrieval)

**Aktuell verfÃ¼gbar:**

```python
# Option A: database_queries.py (empfohlen)
from gw2ml.data.database_queries import get_prices

df = get_prices(
    connection,
    item_id=19697,
    last_days=30
)

# Option B: DataRetriever (komplexer)
from gw2ml.data.retriever import DataRetriever

retriever = DataRetriever()
df = retriever.get_data(
    symbol="19697",
    source="DAMU",
    start_time=...,
    end_time=...
)
```

**âš ï¸ Verbesserungspotential:** Siehe Abschnitt unten

---

### 3ï¸âƒ£ TRANSFORM (DataFrame â†’ TimeSeries)

```python
import pandas as pd
from darts import TimeSeries

# 1. Datetime setzen
df['fetched_at'] = pd.to_datetime(df['fetched_at'])
df = df.set_index('fetched_at').sort_index()

# 2. Timezone entfernen (Darts mag keine Timezones)
if df.index.tz is not None:
    df.index = df.index.tz_localize(None)

# 3. Zu TimeSeries konvertieren
series = TimeSeries.from_dataframe(df, value_cols=['buy_unit_price'])
```

**âš ï¸ Verbesserungspotential:** Helper-Funktion erstellen

---

### 4ï¸âƒ£ TRAINING

```python
# Split
train, test = series.split_after(0.8)

# Fit
model.fit(train)
```

---

### 5ï¸âƒ£ FORECAST

**Single Prediction:**
```python
forecast = model.predict(n=12)  # 12 Steps = 1 Stunde
```

**Backtesting (Walk-Forward):**
```python
forecasts = model.historical_forecasts(
    series=series,
    start=0.5,           # Ab 50% der Daten
    forecast_horizon=12, # 12 Steps voraus
    stride=1,            # Jeden Schritt
    retrain=False        # Nicht neu trainieren
)
```

---

### 6ï¸âƒ£ AUSWERTEN

```python
from darts.metrics import mape, rmse, mae, smape

metrics = {
    "mape": mape(actual, forecast),
    "rmse": rmse(actual, forecast),
    "mae": mae(actual, forecast),
    "smape": smape(actual, forecast),
}
```

---

## ðŸ”´ Verbesserungspotential

### A. Daten Laden (PrioritÃ¤t: HOCH)

**Problem:** Aktuell gibt es zwei Wege (`get_prices`, `DataRetriever`) die nicht konsistent sind.

**Vorschlag: Einfache Wrapper-Funktion**

```mermaid
flowchart TD
    subgraph CURRENT["âŒ Aktuell: 2 Wege"]
        C1["get_prices()"]
        C2["DataRetriever.get_data()"]
    end
    
    subgraph PROPOSED["âœ… Vorschlag: 1 einfacher Weg"]
        P1["get_gw2_prices(item_id, days_back)"]
        P2["â†’ DataFrame"]
    end
    
    CURRENT -.->|"vereinfachen"| PROPOSED
```

**Neue Funktion:**

```python
# src/gw2ml/data/loaders.py

def get_gw2_prices(
    item_id: int,
    days_back: int = 30,
    value_column: str = "buy_unit_price"
) -> pd.DataFrame:
    """
    Einfachster Weg um GW2 Preisdaten zu laden.
    
    Returns:
        DataFrame mit Spalten: fetched_at, {value_column}
        Sortiert nach Zeit, bereit fÃ¼r TimeSeries Konvertierung.
    """
    from .database_queries import get_prices
    from .database_client import DatabaseClient
    
    client = DatabaseClient.from_env()
    df = get_prices(client, item_id, last_days=days_back)
    
    # Nur benÃ¶tigte Spalten
    df = df[['fetched_at', value_column]].copy()
    df = df.sort_values('fetched_at')
    
    return df
```

---

### B. Transform (PrioritÃ¤t: MITTEL)

**Problem:** TimeSeries-Konvertierung ist immer gleich, aber wird Ã¼berall neu geschrieben.

**Vorschlag: Helper-Funktion**

```python
# src/gw2ml/data/loaders.py

def to_timeseries(
    df: pd.DataFrame,
    time_col: str = "fetched_at",
    value_col: str = "buy_unit_price"
) -> TimeSeries:
    """
    Konvertiert DataFrame zu Darts TimeSeries.
    Behandelt Timezone-Probleme automatisch.
    """
    from darts import TimeSeries
    
    df = df.copy()
    df[time_col] = pd.to_datetime(df[time_col])
    
    if df[time_col].dt.tz is not None:
        df[time_col] = df[time_col].dt.tz_localize(None)
    
    df = df.set_index(time_col).sort_index()
    
    return TimeSeries.from_dataframe(df, value_cols=[value_col])
```

---

### C. All-in-One Loader (PrioritÃ¤t: MITTEL)

**Kombination aus A + B:**

```python
# src/gw2ml/data/loaders.py

def load_gw2_series(
    item_id: int,
    days_back: int = 30,
    value_column: str = "buy_unit_price"
) -> TimeSeries:
    """
    LÃ¤dt GW2 Daten und gibt direkt eine TimeSeries zurÃ¼ck.
    
    Example:
        series = load_gw2_series(19697, days_back=30)
        train, test = series.split_after(0.8)
    """
    df = get_gw2_prices(item_id, days_back, value_column)
    return to_timeseries(df, value_col=value_column)
```

---

### D. Caching (PrioritÃ¤t: NIEDRIG)

**Problem:** Bei wiederholten Experimenten werden Daten immer neu aus DB geladen.

**Vorschlag:**

```python
@functools.lru_cache(maxsize=100)
def load_gw2_series_cached(item_id: int, days_back: int) -> TimeSeries:
    """Cached Version fÃ¼r wiederholte Experimente."""
    return load_gw2_series(item_id, days_back)
```

---

## ðŸ“Š Zusammenfassung: Was fehlt?

```mermaid
flowchart TD
    subgraph EXISTS["âœ… Existiert bereits"]
        E1["PostgreSQL DB"]
        E2["get_prices()"]
        E3["DataRetriever"]
        E4["Darts Models"]
        E5["MLflow"]
        E6["Metriken"]
    end
    
    subgraph MISSING["ðŸ”´ Fehlt noch"]
        M1["BaseModel ABC"]
        M2["ARIMAModel"]
        M3["ExpSmoothingModel"]
        M4["BasePipeline ABC"]
        M5["StandardPipeline"]
        M6["Model Registry"]
        M7["Einfacher Data Loader"]
        M8["TimeSeries Helper"]
    end
    
    subgraph NICE["ðŸŸ¡ Nice-to-Have"]
        N1["Caching"]
        N2["Hyperparameter Search"]
        N3["Multiple Items parallel"]
    end
```

---

## ðŸš€ Empfohlene Reihenfolge

| Prio | Was | Warum |
|------|-----|-------|
| 1 | `load_gw2_series()` Helper | Einfachster Einstieg, wird Ã¼berall gebraucht |
| 2 | `BaseModel` + `ARIMAModel` | Basis fÃ¼r alle Modelle |
| 3 | `ExponentialSmoothingModel` | Zweites Basis-Modell |
| 4 | `BasePipeline` + `StandardPipeline` | Orchestrierung |
| 5 | Model Registry | Erweiterbarkeit |
| 6 | Caching | Performance (optional) |

---

## ðŸ’¡ Quick Start nach Implementierung

```python
# So einfach soll es sein:

from gw2ml.data import load_gw2_series
from gw2ml.modeling import ARIMAModel
from gw2ml.pipeline import StandardPipeline

# Daten laden (1 Zeile!)
series = load_gw2_series(item_id=19697, days_back=30)

# Pipeline erstellen
model = ARIMAModel(p=2, d=1, q=2)
pipeline = StandardPipeline(model, "my_experiment")

# AusfÃ¼hren mit Backtesting
results = pipeline.run(series, mode="backtest")

print(f"MAPE: {results['metrics']['mape']:.2f}%")
```

